MODEL:
  BACKBONE:
    FREEZE_AT: 0
    NAME: "build_resnet_backbone"
  WEIGHTS: "models/coco_instance/r50/model_final_3c8ec9.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  MASK_ON: True
  RESNETS:
    DEPTH: 50
    STEM_TYPE: "basic"  # not used
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
    # NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 1, 1]  # not used
DATASETS:
  TRAIN: ("kittimots_train",)
  TEST: ("kittimots_val",)
SOLVER:
  IMS_PER_BATCH: 64
  BASE_LR: 0.00005
  STEPS: (2500,)
  MAX_ITER: 70000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.05
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
INPUT:
  DATASET_MAPPER_NAME: "youtube_vis"
  IGNORE_VALUE: -100
  SAMPLING_FRAME_NUM: 4
  SAMPLING_FRAME_RANGE: 4
  MIN_SIZE_TRAIN_SAMPLING: "choice_by_clip"
  RANDOM_FLIP: "flip_by_clip"
  AUGMENTATIONS: []
  MIN_SIZE_TRAIN: (720,1242)
  MIN_SIZE_TEST: 720
  CROP:
    ENABLED: False
    TYPE: "absolute_range"
    SIZE: (600, 720)
  FORMAT: "RGB"
  SUBSET: False
TEST:
  EVAL_PERIOD: 0
  GT_DIR: "data/KITTI_MOTS/val/"
  OUTPUT_DIR: "new/"
  EVAL_MODE: "train"
  SEQMAP: "external/mots_tools/mots_eval/val.seqmap"
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
VERSION: 2
SEED: 1
